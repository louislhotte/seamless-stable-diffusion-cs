{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Main Workflow - Seamless Stable Diffusion CS</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>\n",
    "\n",
    "<center><img src='https://netacad.centralesupelec.fr/img/cs.jpg' width=200></center>\n",
    "\n",
    "<h4><center>Louis LHOTTE | Cl√©ment VERON | Edouard SEGUIER</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Observation and Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> After conducting tests, we realized that some additions were somewhat weird and unrealistic compared to the original image. For instance, adding headphones to a regular photo consistently (across three attempts) resulted in an outlier (very strange style) or half-headphones with poorly matched colors. The idea, therefore, is to add a <b>blending / filtering</b> step to the pipeline so that the headphones integrate better into the photo (aiming for realism and seamless integration).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = cv2.imread('sylvie.jpg')\n",
    "modified_img = cv2.imread('headphones.png')\n",
    "\n",
    "if original_img.shape[:2] != modified_img.shape[:2]:\n",
    "    modified_img = cv2.resize(modified_img, (original_img.shape[1], original_img.shape[0]))\n",
    "\n",
    "diff_mask = cv2.absdiff(original_img, modified_img)\n",
    "gray_diff_mask = cv2.cvtColor(diff_mask, cv2.COLOR_BGR2GRAY)\n",
    "_, binary_diff_mask = cv2.threshold(gray_diff_mask, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "x, y, w, h = cv2.boundingRect(binary_diff_mask)\n",
    "center = (x + w // 2, y + h // 2)\n",
    "\n",
    "original_img_lab = cv2.cvtColor(original_img, cv2.COLOR_BGR2LAB)\n",
    "modified_img_lab = cv2.cvtColor(modified_img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "l_orig, a_orig, b_orig = cv2.split(original_img_lab)\n",
    "l_mod, a_mod, b_mod = cv2.split(modified_img_lab)\n",
    "\n",
    "a_mod = cv2.addWeighted(a_mod, 0.9, a_orig, 0.1, 0)\n",
    "b_mod = cv2.addWeighted(b_mod, 0.9, b_orig, 0.1, 0)\n",
    "\n",
    "modified_img_lab = cv2.merge((l_mod, a_mod, b_mod))\n",
    "modified_img = cv2.cvtColor(modified_img_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "mask = cv2.absdiff(original_img, modified_img)\n",
    "gray_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "_, binary_mask = cv2.threshold(gray_mask, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Apply feathering to the mask\n",
    "feathered_mask = cv2.GaussianBlur(binary_mask, (21, 21), 0)\n",
    "\n",
    "blended_img = cv2.seamlessClone(modified_img, original_img, feathered_mask, center, cv2.NORMAL_CLONE)\n",
    "\n",
    "cv2.imwrite('blended_output.jpg', blended_img)\n",
    "cv2.imshow('Blended Image', blended_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
