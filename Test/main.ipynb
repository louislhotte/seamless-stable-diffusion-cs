{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Evaluation pipeline</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>\n",
    "\n",
    "<center><img src='https://netacad.centralesupelec.fr/img/cs.jpg' width=200></center>\n",
    "\n",
    "<h4><center>Louis LHOTTE | Cl√©ment VERON | Edouard SEGUIER</center></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_images_with_clip(image_1_path, image_2_path, prompt):\n",
    "    \"\"\"\n",
    "    Evaluate two images based on their relevance to a given text prompt using the CLIP metric.\n",
    "\n",
    "    Args:\n",
    "        image_1_path (str): Path to the first image.\n",
    "        image_2_path (str): Path to the second image.\n",
    "        prompt (str): The text prompt for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing similarity scores for each image.\n",
    "    \"\"\"\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    image_1 = Image.open(image_1_path).convert(\"RGB\")\n",
    "    image_2 = Image.open(image_2_path).convert(\"RGB\")\n",
    "    inputs = processor(text=[prompt], images=[image_1, image_2], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    image_embeddings = outputs.image_embeds\n",
    "    text_embeddings = outputs.text_embeds\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(image_embeddings, text_embeddings)\n",
    "\n",
    "    result = {\n",
    "        \"image_1_score\": similarity[0].item(),\n",
    "        \"image_2_score\": similarity[1].item(),\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image Score: 0.2334834784269333\n",
      "Ouput image Score: 0.2928134500980377\n",
      "Delta Image: 0.05932997167110443\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_1_path = \"input.jpg\"\n",
    "    image_2_path = \"output.png\"\n",
    "    prompt = \"Transform this image into a clean, sharp, modern, bold 2D logo design for a mountaineering company. Integrate sharp and minimalistic design elements, the whole image should be transformed into a traditional logo\"\n",
    "\n",
    "    scores = evaluate_images_with_clip(image_1_path, image_2_path, prompt)\n",
    "    print(\"Input image Score:\", scores[\"image_1_score\"])\n",
    "    print(\"Ouput image Score:\", scores[\"image_2_score\"])\n",
    "    print(\"Delta Image:\", scores[\"image_2_score\"] - scores[\"image_1_score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
